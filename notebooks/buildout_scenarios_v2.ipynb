{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wind scenarios for buildout ACTIVSg grids\n",
    "\n",
    "* conda: buildouts\n",
    "\n",
    "* buildouts with new wind generators\n",
    "* reading pre-made tables generated  part1 & part2 notebooks (save_dir)\n",
    "* tamu200_buildout_part1.ipynb\n",
    "* tamu200_buildout_part2.ipynb\n",
    "\n",
    "#### ignore below buttet points:\n",
    "* JHub:/projects/ecp/powerscenarios/notebooks/eagle_dev/tamu200_buildout_part1.ipynb\n",
    "* JHub:/projects/ecp/powerscenarios/notebooks/eagle_dev/tamu200_buildout_part2.ipynb\n",
    "* local mac: conda activate py3n\n",
    "* /Users/isatkaus/projects/ecp/public-github/powerscenarios/notebooks/dev/buildouts/\n",
    "* eagle: conda rtpv-eagle\n",
    "* JHub: /home/isatkaus/projects/ecp/powerscenarios/notebooks/eagle_dev/\n",
    "* similar to:\n",
    "* projects/ecp/public-github/powerscenarios/notebooks/dev/buildouts/buildout_scenarios.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll2 = [\"blet\", \"test\", \"black\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cufflinks as cl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # set PYWTK_CACHE_DIR to locate WIND Toolkit data\n",
    "# # will download from AWS as needed\n",
    "# os.environ[\"PYWTK_CACHE_DIR\"] = os.path.join(os.environ[\"HOME\"], \"pywtk-data\")\n",
    "\n",
    "from powerscenarios.parser import Parser\n",
    "# from powerscenarios.grid import Grid\n",
    "from powerscenarios.grid_copy2 import Grid\n",
    "\n",
    "# show multiple cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# plotting (optional)\n",
    "\n",
    "cl.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext nb_black\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse TAMU grid .aux files\n",
    "* these are original grid files\n",
    "* later we'll read modified grid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose TAMU grid\n",
    "# grid files can be downloaded from:\n",
    "# https://electricgrids.engr.tamu.edu/electric-grid-test-cases/\n",
    "\n",
    "grid_name = \"ACTIVSg200\"  # TAMU 200 bus case\n",
    "# grid_name = \"ACTIVSg2000\"  # TAMU 2000 bus case\n",
    "# grid_name = \"ACTIVSg10k\"  # TAMU 10000 bus case\n",
    "\n",
    "# path to .aux file (TAMU grids) obtained from e.g.\n",
    "# https://electricgrids.engr.tamu.edu/electric-grid-test-cases/activsg200/\n",
    "# local:\n",
    "# data_dir = \"../../../data/grid-data/\"\n",
    "# on Eagle/Kestrel:\n",
    "data_dir = \"/projects/hpcapps/isatkaus/grid-buildouts-data/grid-data/\"\n",
    "# aux_file_name = data_dir + grid_name + \"/\" + grid_name + \".aux\"\n",
    "aux_file_name = os.path.join(data_dir, grid_name, grid_name + \".aux\")\n",
    "\n",
    "# parse original .aux file and return dataframes for buses, generators, and wind generators\n",
    "# here, we need .aux files because those are the only ones with Latitute/Longitude information\n",
    "parser = Parser()\n",
    "bus_df, gen_df, wind_gen_df = parser.parse_tamu_aux(aux_file_name)\n",
    "\n",
    "# see what you got\n",
    "print(\"bus_df:\")\n",
    "bus_df.head()\n",
    "print(\"gen_df:\")\n",
    "gen_df.head()\n",
    "print(\"wind_gen_df:\")\n",
    "wind_gen_df\n",
    "\n",
    "print(\"\\n original grid:\")\n",
    "grid = Grid(grid_name, bus_df, gen_df, wind_gen_df)\n",
    "grid\n",
    "print(grid.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# or parse RTS grid .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # RTS-GMLC grid\n",
    "# # https://github.com/GridMod/RTS-GMLC\n",
    "# grid_name = \"RTS\"\n",
    "\n",
    "# data_dir = \"../data/grid-data\"\n",
    "\n",
    "# bus_csv_filename = os.path.join(data_dir, grid_name, \"bus.csv\")\n",
    "# gen_csv_filename = os.path.join(data_dir, grid_name, \"gen.csv\")\n",
    "\n",
    "# parser = Parser()\n",
    "\n",
    "# # if solar2wind, will replace all solar to wind\n",
    "# bus_df, gen_df, wind_gen_df = parser.parse_rts_csvs(\n",
    "#     bus_csv_filename, gen_csv_filename, solar2wind=False\n",
    "# )\n",
    "\n",
    "# # see what you got\n",
    "# print(\"bus_df:\")\n",
    "# bus_df.head()\n",
    "# print(\"gen_df:\")\n",
    "# gen_df.head()\n",
    "# print(\"wind_gen_df:\")\n",
    "# wind_gen_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read pre-made tables and modified grid files\n",
    "* chose the buildout configuration by setting \"buildout_dir\"\n",
    "* buildout tables/grid files generated on Eagle with:\n",
    "* tamu200_buildout_part1.ipynb\n",
    "* tamu200_buildout_part2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# read instead of retrieve_wind_sites\n",
    "###################################################################\n",
    "\n",
    "# ### tables with Pmax from .m files\n",
    "# table_dir = \"/Users/isatkaus/projects/ecp/public-github/powerscenarios/data/tables-data/m-file-Pmax/\"\n",
    "\n",
    "\n",
    "# buildout dir: choose level 1,2,4,6,8, or 10\n",
    "# buildout_level = 1\n",
    "# ###\n",
    "# table_dir = \"/Users/isatkaus/projects/ecp/public-github/powerscenarios/data/tables-data/buildouts/orig_wind_locs/nameplate_x_{}/\".format(\n",
    "#     buildout_level\n",
    "# )\n",
    "\n",
    "########################################################\n",
    "# CHOOSE BUILDOUT\n",
    "# buildout_dir (contains tables and grid files )\n",
    "# buildout_name = \"ngens89-pen69\"\n",
    "# buildout_name = \"option2_seed2-ngens11-pen86\"\n",
    "buildout_name = \"option2_seed2-ngens10-pen89\"\n",
    "# buildout_name = \"option2_seed2-ngens12-pen134\"\n",
    "# ### local\n",
    "# buildout_dir = f\"/Users/isatkaus/projects/ecp/public-github/powerscenarios/data/tables-data/buildouts/{buildout_name}\"\n",
    "\n",
    "# Eagle/Kestrel\n",
    "# buildout_dir = f\"/projects/exasgd/isatkaus/buildout/wind/wind_gen_tamu5/buildouts/work-dir/{buildout_name}\"\n",
    "buildout_dir = f\"/projects/hpcapps/isatkaus/grid-buildouts-data/rev-runs/wind-gen-tamu200-v8/buildouts/work-dir/{buildout_name}\"\n",
    "\n",
    "\n",
    "# if using modified wind gens (new generators) also need\n",
    "# new: bus_df, gen_df and wind_gen_df\n",
    "filename = \"bus_df.csv\"\n",
    "bus_df = pd.read_csv(os.path.join(buildout_dir, filename), index_col=0)\n",
    "print(\"\\nbus_df:\")\n",
    "bus_df\n",
    "\n",
    "filename = \"gen_df.csv\"\n",
    "gen_df = pd.read_csv(os.path.join(buildout_dir, filename), index_col=0)\n",
    "print(\"\\ngen_df:\")\n",
    "gen_df\n",
    "\n",
    "filename = \"wind_gen_df.csv\"\n",
    "wind_gen_df = pd.read_csv(os.path.join(buildout_dir, filename), index_col=0)\n",
    "print(\"\\nwind_gen_df:\")\n",
    "wind_gen_df\n",
    "\n",
    "\n",
    "# to instantiate a grid we need: name, bus, generator, and wind generator dataframes from Parser\n",
    "# really, we only wind generators, will change in the future\n",
    "grid = Grid(grid_name, bus_df, gen_df, wind_gen_df)\n",
    "grid\n",
    "print(grid.info())\n",
    "\n",
    "tables_dir = os.path.join(buildout_dir, \"tables-data\")\n",
    "\n",
    "filename = \"{}_wind_sites_df.h5\".format(grid_name)\n",
    "grid.wind_sites = pd.read_hdf(os.path.join(tables_dir, filename))\n",
    "print(\"\\n wind sites\")\n",
    "grid.wind_sites\n",
    "\n",
    "# read instead of make_tables\n",
    "filename = \"{}_actuals_df.h5\".format(grid_name)\n",
    "grid.actuals = pd.read_hdf(os.path.join(tables_dir, filename))\n",
    "print(\"\\n actuals\")\n",
    "grid.actuals\n",
    "filename = \"{}_scenarios_df.h5\".format(grid_name)\n",
    "grid.scenarios = pd.read_hdf(os.path.join(tables_dir, filename))\n",
    "print(\"\\n scenarios\")\n",
    "grid.scenarios\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for actuals, make year you want: NOTE watch out for leap year!!!\n",
    "# if actuals from tables are usually 2007, so if you change to 2020 you'll be missing\n",
    "# Feb 29th will not exist\n",
    "# if, on the other hand, actuals from tables are for 2008, then last day in December\n",
    "# will be missing, since reV can only generate 365 days\n",
    "\n",
    "##########################################################################\n",
    "# for tamu200, load is in 2017, so we will remap actuals to 2017\n",
    "# not a leap year, so everuthing should work as expected\n",
    "\n",
    "grid.actuals.index = grid.actuals.index.map(lambda t: t.replace(year=2017))\n",
    "# see what you got\n",
    "print(\"\\nactuals_df:\")\n",
    "grid.actuals\n",
    "print(\"\\nscenarios_df:\")\n",
    "grid.scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select interesting time period for scenario generation\n",
    "* e.g., find timestamps matching initial wind power on the network\n",
    "* we want to match wind power Pg in .m file, else \"ExaGO will not converge\"\n",
    "* find timestamps witihin delta, then random sample \n",
    "### can use dash-app for spatio-temporal viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# plotting total wind power of actuals\n",
    "# to select sim_timestamps accordingly\n",
    "\n",
    "t1 = pd.Timestamp(\"2017-07-01 00:15:00+0000\", tz=\"UTC\")\n",
    "t2 = pd.Timestamp(\"2017-07-07 00:15:00+0000\", tz=\"UTC\")\n",
    "grid.actuals.loc[t1:t2, \"TotalPower\"].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### find actual date matching (within delta) the Pq power in the .m file\n",
    "\n",
    "# print(\"\\ntotal Pg (.m) wind power on the network:\")\n",
    "# total_Pg = wind_gen_m_df[\"Pg\"].sum()\n",
    "# total_Pg\n",
    "\n",
    "# ## .m file has 12776 MW of wind\n",
    "# ## to do sampling from mid bin 10%-90% we should pick total power below 12360\n",
    "# total_Pg = 12100\n",
    "\n",
    "# delta = 20\n",
    "# sim_timestamp = (\n",
    "#     grid.actuals.loc[\n",
    "#         (grid.actuals[\"TotalPower\"] > total_Pg - delta)\n",
    "#         & (grid.actuals[\"TotalPower\"] < total_Pg + delta)\n",
    "#     ]\n",
    "#     .sample()\n",
    "#     .index[0]\n",
    "# )\n",
    "\n",
    "# sim_timestamp\n",
    "\n",
    "# grid.actuals.loc[sim_timestamp:sim_timestamp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate_wind_scenarios\n",
    "* one timestamp\n",
    "* outputs p_bin and cost_n\n",
    "* full pipeline a few cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# time period for which to generate scenarios\n",
    "\n",
    "# sim timestamp\n",
    "sim_timestamp = pd.Timestamp(\"2017-07-01 11:25:00+0000\", tz=\"UTC\")\n",
    "\n",
    "\n",
    "# other parameters\n",
    "sampling_method = \"monte carlo\"\n",
    "fidelity = None\n",
    "\n",
    "# sampling_method = \"importance\"\n",
    "# fidelity = \"checkmark\"\n",
    "\n",
    "# fidelity = \"exago_file\"\n",
    "n_scenarios = 10\n",
    "n_periods = 6\n",
    "\n",
    "# random_seed = np.random.randint(2 ** 31 - 1)\n",
    "random_seed = 20\n",
    "random_seed\n",
    "\n",
    "scenarios_df, weights_df, p_bin, cost_n = grid.generate_wind_scenarios(\n",
    "    sim_timestamp,\n",
    "    power_quantiles=[0.0, 0.20, 0.80, 1.0],\n",
    "    sampling_method=sampling_method,\n",
    "    fidelity=fidelity,\n",
    "    n_scenarios=n_scenarios,\n",
    "    n_periods=n_periods,\n",
    "    # random_seed=6,\n",
    "    random_seed=random_seed,\n",
    "    output_format=0,\n",
    ")\n",
    "\n",
    "\n",
    "# copy wanted actuals\n",
    "actuals_df = (\n",
    "    grid.actuals.loc[sim_timestamp:sim_timestamp].drop(\n",
    "        \"TotalPower\", axis=1).copy()\n",
    ")\n",
    "# match index name to all_scenarios_df\n",
    "actuals_df.index.name = \"sim_timestamp\"\n",
    "\n",
    "print(\"\\nactuals_df:\")\n",
    "actuals_df\n",
    "print(\"\\nscenarios_df:\")\n",
    "scenarios_df\n",
    "print(\"\\nweights_df:\")\n",
    "weights_df\n",
    "\n",
    "print(\"\\np_bin:\")\n",
    "p_bin\n",
    "\n",
    "print(\"\\ncost_n\")\n",
    "cost_n\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"elapsed time = {}\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = pd.Timestamp(\"2008-01-03 00:07:30+00:00\")\n",
    "# end = pd.Timestamp(\"2008-01-04 00:09:00+00:00\")\n",
    "# dev_s = grid.scenarios.loc[cost_n.loc[start:end].index, \"Deviation\"]\n",
    "# # dev_s\n",
    "# cost_s = cost_n.loc[start:end]\n",
    "# power_s = grid.scenarios.loc[cost_n.loc[start:end].index, \"TotalPower\"]\n",
    "# # cost_s\n",
    "# plot_df = pd.DataFrame(index=dev_s.index)\n",
    "# plot_df[\"deviation\"] = dev_s\n",
    "# plot_df[\"cost\"] = cost_s\n",
    "# plot_df[\"power\"] = power_s\n",
    "# plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total power\n",
    "# choose sim_timestamp for which to plot all scenarios\n",
    "# sim_timestamp = sim_timestamps[0]\n",
    "\n",
    "# all needed period timestamps: t0,t1,...\n",
    "timestamps = pd.date_range(\n",
    "    start=sim_timestamp - pd.Timedelta(\"5min\"), periods=n_periods + 1, freq=\"5min\"\n",
    ")\n",
    "plot_df = pd.DataFrame(\n",
    "    index=timestamps,\n",
    "    columns=range(1, n_scenarios + 1),\n",
    ")\n",
    "for scenario_nr in range(1, n_scenarios + 1):\n",
    "    s = scenarios_df.loc[\n",
    "        (\n",
    "            sim_timestamp,\n",
    "            scenario_nr,\n",
    "        )\n",
    "    ].sum(axis=1)\n",
    "    s.loc[timestamps[0]] = grid.actuals.loc[timestamps[0]].loc[\"TotalPower\"]\n",
    "\n",
    "    plot_df[scenario_nr] = s\n",
    "\n",
    "# plot_df.iplot()\n",
    "# plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"Total Wind Power\", asImage=True,)\n",
    "plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"Total Wind Power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate scenarios for a period of time one buildout level\n",
    "* come from buildout_scenarios_to_julia.ipynb (end of notebook)\n",
    "* saving two cells below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# time period for which to generate scenarios\n",
    "\n",
    "# # a few timestamps timestamp\n",
    "# sim_timestamps = [\n",
    "#     pd.Timestamp(\"2020-07-01 00:15:00+0000\", tz=\"UTC\"),\n",
    "# ]\n",
    "# sim_timestamps = [pd.Timestamp(\"2020-07-01 00:15:00+0000\", tz=\"UTC\"),pd.Timestamp(\"2020-07-01 00:20:00+0000\", tz=\"UTC\")]\n",
    "\n",
    "# range\n",
    "sim_timestamps = pd.date_range(\n",
    "    start=pd.Timestamp(\"2017-06-01 00:00:00+0000\", tz=\"UTC\"),\n",
    "    end=pd.Timestamp(\"2017-08-30 00:00:00+0000\", tz=\"UTC\"),\n",
    "    freq=\"5min\",\n",
    ")\n",
    "\n",
    "\n",
    "# other parameters\n",
    "sampling_method = \"monte carlo\"\n",
    "# sampling_method = \"importance\"\n",
    "# fidelity = \"checkmark\"\n",
    "n_scenarios = 1\n",
    "n_periods = 1\n",
    "\n",
    "########################################################\n",
    "\n",
    "all_weights_df = pd.DataFrame(\n",
    "    index=sim_timestamps, columns=range(1, n_scenarios + 1))\n",
    "\n",
    "# create multiindex df for all generated scenarios\n",
    "# three arrays for multiindex:\n",
    "a1 = [x for x in sim_timestamps for k in range(n_scenarios * n_periods)]\n",
    "a2 = [x for x in range(1, n_scenarios + 1) for k in range(n_periods)] * len(\n",
    "    sim_timestamps\n",
    ")\n",
    "a3 = [\n",
    "    t + pd.Timedelta(\"5min\") * k\n",
    "    for t in sim_timestamps\n",
    "    for k in list(range(n_periods)) * n_scenarios\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_arrays(\n",
    "    [a1, a2, a3], names=[\"sim_timestamp\", \"scenario_nr\", \"period_timestamp\"]\n",
    ")\n",
    "all_scenarios_df = pd.DataFrame(\n",
    "    index=index, columns=grid.wind_generators[\"GenUID\"].values\n",
    ")\n",
    "\n",
    "\n",
    "for sim_timestamp in sim_timestamps:\n",
    "    print(\"sim_timestamp = {}\".format(sim_timestamp))\n",
    "    random_seed = np.random.randint(2**31 - 1)\n",
    "    # random_seed = 594081473\n",
    "    print(\"random_seed = {}\".format(random_seed))\n",
    "    scenarios_df, weights_df, p_bin, cost_n = grid.generate_wind_scenarios(\n",
    "        sim_timestamp,\n",
    "        power_quantiles=[0.0, 0.20, 0.80, 1.0],\n",
    "        sampling_method=sampling_method,\n",
    "        fidelity=fidelity,\n",
    "        n_scenarios=n_scenarios,\n",
    "        n_periods=n_periods,\n",
    "        # random_seed=6,\n",
    "        random_seed=random_seed,\n",
    "        output_format=0,\n",
    "    )\n",
    "    # all_scenarios_df=pd.concat([all_scenarios_df,scenarios_df])\n",
    "    all_scenarios_df.loc[sim_timestamp] = scenarios_df\n",
    "\n",
    "    # all_weights_df=pd.concat([all_weights_df,weights_df])\n",
    "    all_weights_df.loc[sim_timestamp] = weights_df.loc[sim_timestamp]\n",
    "\n",
    "\n",
    "# copy wanted actuals\n",
    "all_actuals_df = grid.actuals.loc[sim_timestamps].drop(\n",
    "    \"TotalPower\", axis=1).copy()\n",
    "# match index name to all_scenarios_df\n",
    "all_actuals_df.index.name = \"sim_timestamp\"\n",
    "\n",
    "print(\"\\nall_actuals_df:\")\n",
    "all_actuals_df\n",
    "print(\"\\nall_scenarios_df:\")\n",
    "all_scenarios_df\n",
    "print(\"\\nall_weights_df:\")\n",
    "all_weights_df\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"elapsed time = {}\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n actuals max:\")\n",
    "s1 = all_actuals_df.max()\n",
    "s1 = s1.sort_index()\n",
    "s1.index = s1.index.map(lambda x: x.replace(\"Wind\", \"WIND\"))\n",
    "s1\n",
    "print(\"\\n max cap of wind gens:\")\n",
    "s2 = grid.wind_generators.set_index(\"GenUID\")[\"GenMWMax\"]\n",
    "s2.index = s2.index.map(lambda x: x.replace(\"Wind\", \"WIND\"))\n",
    "s2 = s2.sort_index()\n",
    "\n",
    "print(\"\\n any actuals > that GenMWMax?\")\n",
    "s1 > s2\n",
    "\n",
    "print(\"\\n max wind gen production is within 10% of wind gen capacities:\")\n",
    "abs((s1.sort_index() - s2.sort_index()).sum()) * 0.1 < s2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save scenarios for one buildout level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildout_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for julia\n",
    "# base_dir = \"/Users/isatkaus/projects/ecp/julia/notebooks/buildouts/\"\n",
    "\n",
    "# save_dir = os.path.join(buildout_dir,\"scenarios/month-of-july\")\n",
    "save_dir = os.path.join(buildout_dir, \"scenarios/summer\")\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "##############\n",
    "# actuals\n",
    "##############\n",
    "\n",
    "# rename columns to match Maack's convention\n",
    "all_actuals_df.index.rename(\"DateTime\", inplace=True)\n",
    "# all_actuals_df.drop(\"TotalPower\",axis=1, inplace=True)\n",
    "\n",
    "old_names = all_actuals_df.columns.values\n",
    "new_names = [name.replace(\"Wind\", \"WIND\") for name in old_names]\n",
    "all_actuals_df.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "\n",
    "# drop tz, then julia's CSV can parse dates\n",
    "all_actuals_df.index = all_actuals_df.index.map(\n",
    "    lambda t: t.replace(tzinfo=None))\n",
    "\n",
    "all_actuals_df\n",
    "\n",
    "filename = \"actuals_\" + grid_name + \".csv\"\n",
    "all_actuals_df.to_csv(os.path.join(save_dir, filename))\n",
    "\n",
    "\n",
    "##############\n",
    "# scenarios\n",
    "##############\n",
    "\n",
    "old_names = all_scenarios_df.columns.values\n",
    "new_names = [name.replace(\"Wind\", \"WIND\") for name in old_names]\n",
    "all_scenarios_df.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "\n",
    "# drop tz from scenarios as well, then julia's CSV can parse dates\n",
    "all_scenarios_df.index = all_scenarios_df.index.map(\n",
    "    lambda t: (t[0].replace(tzinfo=None), t[1], t[2].replace(tzinfo=None))\n",
    ")\n",
    "all_scenarios_df\n",
    "\n",
    "\n",
    "if sampling_method == \"monte carlo\":\n",
    "    method_str = \"MC\"\n",
    "else:\n",
    "    method_str = \"IS\"\n",
    "\n",
    "filename = 'scenarios_{}_{}_{}per_{}scen.csv'.format(\n",
    "    grid_name, method_str, n_periods, n_scenarios)\n",
    "all_scenarios_df.to_csv(os.path.join(save_dir, filename))\n",
    "\n",
    "\n",
    "######################################################\n",
    "# also copy ACTIVSg200_m_gen.csv that was modified by the buildout\n",
    "# and ACTIVSg200_m_bus.csv, ACTIVSg200_m_branch.csv that were not modified by buildout\n",
    "# that way loading grid files in julia will be easy by pointing to the right dir\n",
    "# ######################################################\n",
    "# import shutil\n",
    "# filename = \"ACTIVSg200_m_gen.csv\"\n",
    "# ### table_dir = buildout_dir\n",
    "# src = os.path.join(table_dir, filename)\n",
    "# dst = os.path.join(save_dir, filename)\n",
    "# shutil.copyfile(src, dst)\n",
    "\n",
    "# orig_grid_data_dir = \"/Users/isatkaus/projects/ecp/powerscenarios/data/grid-data/ACTIVSg200/\"\n",
    "# filename = \"ACTIVSg200_m_bus.csv\"\n",
    "# src = os.path.join(orig_grid_data_dir, filename)\n",
    "# dst = os.path.join(save_dir, filename)\n",
    "# shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "# filename = \"ACTIVSg200_m_branch.csv\"\n",
    "# src = os.path.join(orig_grid_data_dir, filename)\n",
    "# dst = os.path.join(save_dir, filename)\n",
    "# shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total power\n",
    "# choose sim_timestamp for which to plot all scenarios\n",
    "# sim_timestamp = sim_timestamps[0]\n",
    "\n",
    "# all needed period timestamps: t0,t1,...\n",
    "timestamps = pd.date_range(\n",
    "    start=sim_timestamp - pd.Timedelta(\"5min\"), periods=n_periods + 1, freq=\"5min\"\n",
    ")\n",
    "plot_df = pd.DataFrame(\n",
    "    index=timestamps,\n",
    "    columns=range(1, n_scenarios + 1),\n",
    ")\n",
    "for scenario_nr in range(1, n_scenarios + 1):\n",
    "    s = scenarios_df.loc[\n",
    "        (\n",
    "            sim_timestamp,\n",
    "            scenario_nr,\n",
    "        )\n",
    "    ].sum(axis=1)\n",
    "    s.loc[timestamps[0]] = grid.actuals.loc[timestamps[0]].loc[\"TotalPower\"]\n",
    "\n",
    "    plot_df[scenario_nr] = s\n",
    "\n",
    "# plot_df.iplot()\n",
    "# plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"Total Wind Power\", asImage=True,)\n",
    "plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"Total Wind Power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power at generators\n",
    "# choose sim_timestamp and scenario nr for which to plot power at generators\n",
    "# sim_timestamp = sim_timestamps[0]\n",
    "scenario_nr = 5\n",
    "\n",
    "# all needed period timestamps: t0,t1,...\n",
    "timestamps = pd.date_range(\n",
    "    start=sim_timestamp - pd.Timedelta(\"5min\"), periods=n_periods + 1, freq=\"5min\"\n",
    ")\n",
    "\n",
    "plot_df = scenarios_df.loc[(sim_timestamp, scenario_nr)]\n",
    "plot_df.loc[timestamps[0]] = grid.actuals.loc[timestamps[0]]\n",
    "plot_df.sort_index(inplace=True)\n",
    "\n",
    "# plot_df.iplot()\n",
    "# plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"scenario_nr={}\".format(scenario_nr), asImage=True,)\n",
    "plot_df.iplot(\n",
    "    xTitle=\"Time\",\n",
    "    yTitle=\"MW\",\n",
    "    title=\"Power at generators when scenario_nr={}\".format(scenario_nr),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qcut problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actuals: what percentage of time wind gen is at it's max?\n",
    "actuals_df = grid.actuals\n",
    "actuals_df\n",
    "\n",
    "print(\"\\n\\nEXACTLY MAX POWER:\")\n",
    "# exactly maxes\n",
    "for wind_farm in actuals_df.max().index:\n",
    "    print(wind_farm)\n",
    "    maxes_s = actuals_df.loc[actuals_df[wind_farm]\n",
    "                             == actuals_df.max().loc[wind_farm]]\n",
    "\n",
    "    print(\n",
    "        \"wind farm {} run at its max power {} fraction of the time \".format(\n",
    "            wind_farm, round(len(maxes_s) / len(actuals_df), 4)\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"\\n\\nALMOST MAX POWER:\")\n",
    "# almost maxes\n",
    "\n",
    "tol = 1\n",
    "\n",
    "for wind_farm in actuals_df.max().index:\n",
    "    print(wind_farm)\n",
    "    almost_maxes_s = actuals_df[wind_farm].loc[\n",
    "        abs(actuals_df[wind_farm] - actuals_df.max().loc[wind_farm]) < tol\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        \"wind farm {} run at its almost (within {}MW) max power {} fraction of the time \".format(\n",
    "            wind_farm, tol, round(len(almost_maxes_s) / len(actuals_df), 4)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "scenarios_df = grid.scenarios\n",
    "scenarios_df\n",
    "scenarios_df[\"TotalPower\"].min()\n",
    "total_max = scenarios_df[\"TotalPower\"].max()\n",
    "total_max\n",
    "\n",
    "scenarios_df.loc[scenarios_df[\"TotalPower\"] == total_max]\n",
    "\n",
    "n_periods = 1\n",
    "power_quantiles = [0.0, 0.15, 0.85, 1.0]\n",
    "power_bins = pd.qcut(\n",
    "    scenarios_df[\"TotalPower\"].iloc[:-n_periods],\n",
    "    q=power_quantiles,\n",
    ")\n",
    "power_bins\n",
    "\n",
    "for power_bin in power_bins.cat.categories:\n",
    "    power_bin\n",
    "    scenarios_df.loc[power_bins.loc[power_bins == power_bin].index, \"Deviation\"].iplot(\n",
    "        kind=\"hist\", title=\"{}\".format(power_bin)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save for Shri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actuals_df.drop(pd.Timestamp(\"2020-08-01 00:10:00+00:00\"), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir scenarios4shri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = \"./scenarios4shri/checkmark/\"\n",
    "save_dir = \"./scenarios4shri/checkmark/ACTIVSg10k/initial_wind_power_12100/\"\n",
    "# save_dir = \"./scenarios4shri/monte_carlo/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_df.loc[sim_timestamp - pd.Timedelta(\"5min\")] = grid.actuals.loc[\n",
    "    sim_timestamp - pd.Timedelta(\"5min\")\n",
    "]\n",
    "actuals_df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "# save actuals_df\n",
    "filename = \"actuals_{}.csv\".format(grid_name)\n",
    "actuals_df.to_csv(os.path.join(save_dir, filename))\n",
    "\n",
    "print(\"\\nsaving actuals to {} \".format(os.path.join(save_dir, filename)))\n",
    "actuals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = scenarios_df.loc[sim_timestamp]\n",
    "# drop period_timestamp multi-index level\n",
    "mindex = s_df.index\n",
    "s_df.index = mindex.droplevel(1)\n",
    "\n",
    "# add weights column\n",
    "s_df[\"weight\"] = weights_df.loc[sim_timestamp]\n",
    "\n",
    "\n",
    "# save scenarios with weights\n",
    "filename = \"{}_scenarios_{}.csv\".format(n_scenarios, grid_name)\n",
    "s_df.to_csv(os.path.join(save_dir, filename))\n",
    "\n",
    "print(\"\\nsaving scenarios to {} \".format(os.path.join(save_dir, filename)))\n",
    "s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if any scenario has a bus with wind power above Pmax of .m file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_gen_df\n",
    "max_power_s = wind_gen_df[[\"GenMWMax\", \"GenUID\"]].set_index(\"GenUID\")[\n",
    "    \"GenMWMax\"]\n",
    "max_power_s\n",
    "\n",
    "\n",
    "print(\"\\nany scenario has a bus with wind power above Pmax of .m file?\")\n",
    "(s_df.drop(\"weight\", axis=1) > max_power_s).any().any()\n",
    "\n",
    "s_df.drop(\"weight\", axis=1) > max_power_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_gen_aux_df[\"GenUID\"]\n",
    "wind_gen_m_df[\"Pmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_gen_m_df.loc[77231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_gen_aux_df[\"GenUID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read scenarios\n",
    "# grid_name = \"ACTIVSg200\"\n",
    "n_scenarios = 10\n",
    "filename = \"{}_scenarios_{}.csv\".format(n_scenarios, grid_name)\n",
    "s_df = pd.read_csv(os.path.join(save_dir, filename), index_col=0)\n",
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.info()\n",
    "s_df.loc[1, \"65_Wind_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df.loc[\n",
    "    (\n",
    "        pd.Timestamp(\"2020-08-01 00:15:00+00:00\"),\n",
    "        1,\n",
    "        pd.Timestamp(\"2020-08-01 00:15:00+00:00\"),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.loc[1, \"65_Wind_1\"]\n",
    "df = s_df.copy().round(decimals=grid.WTK_DATA_PRECISION)\n",
    "\n",
    "# df.round(decimals=grid.WTK_DATA_PRECISION, inplace=True)\n",
    "df.loc[1, \"65_Wind_1\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate_wind_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# time period for which to generate scenarios\n",
    "\n",
    "# a few timestamps timestamp\n",
    "sim_timestamps = [\n",
    "    pd.Timestamp(\"2020-07-01 00:15:00+0000\", tz=\"UTC\"),\n",
    "]\n",
    "# sim_timestamps = [pd.Timestamp(\"2020-07-01 00:15:00+0000\", tz=\"UTC\"),pd.Timestamp(\"2020-07-01 00:20:00+0000\", tz=\"UTC\")]\n",
    "\n",
    "# #range\n",
    "# sim_timestamps = pd.date_range(\n",
    "#    start=pd.Timestamp(\"2020-07-01 00:00:00+0000\", tz=\"UTC\"), end=pd.Timestamp(\"2020-07-07 00:00:00+0000\", tz=\"UTC\"), freq=\"5min\"\n",
    "# )\n",
    "\n",
    "\n",
    "# other parameters\n",
    "# sampling_method=\"monte carlo\"\n",
    "sampling_method = \"importance\"\n",
    "fidelity = \"checkmark\"\n",
    "# fidelity = \"exago_file\"\n",
    "n_scenarios = 3\n",
    "n_periods = 2\n",
    "\n",
    "########################################################\n",
    "\n",
    "all_weights_df = pd.DataFrame(\n",
    "    index=sim_timestamps, columns=range(1, n_scenarios + 1))\n",
    "\n",
    "# create multiindex df for all generated scenarios\n",
    "# three arrays for multiindex:\n",
    "a1 = [x for x in sim_timestamps for k in range(n_scenarios * n_periods)]\n",
    "a2 = [x for x in range(1, n_scenarios + 1) for k in range(n_periods)] * len(\n",
    "    sim_timestamps\n",
    ")\n",
    "a3 = [\n",
    "    t + pd.Timedelta(\"5min\") * k\n",
    "    for t in sim_timestamps\n",
    "    for k in list(range(n_periods)) * n_scenarios\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_arrays(\n",
    "    [a1, a2, a3], names=[\"sim_timestamp\", \"scenario_nr\", \"period_timestamp\"]\n",
    ")\n",
    "all_scenarios_df = pd.DataFrame(\n",
    "    index=index, columns=grid.wind_generators[\"GenUID\"].values\n",
    ")\n",
    "\n",
    "\n",
    "for sim_timestamp in sim_timestamps:\n",
    "    # print(\"sim_timestamp = {}\".format(sim_timestamp))\n",
    "    random_seed = np.random.randint(2 ** 31 - 1)\n",
    "    # random_seed = 594081473\n",
    "    # print(\"random_seed = {}\".format(random_seed))\n",
    "    scenarios_df, weights_df, p_bin, cost_n = grid.generate_wind_scenarios(\n",
    "        sim_timestamp,\n",
    "        power_quantiles=[0.0, 0.1, 0.9, 1.0],\n",
    "        sampling_method=sampling_method,\n",
    "        fidelity=fidelity,\n",
    "        n_scenarios=n_scenarios,\n",
    "        n_periods=n_periods,\n",
    "        # random_seed=6,\n",
    "        random_seed=random_seed,\n",
    "        output_format=0,\n",
    "    )\n",
    "    # all_scenarios_df=pd.concat([all_scenarios_df,scenarios_df])\n",
    "    all_scenarios_df.loc[sim_timestamp] = scenarios_df\n",
    "\n",
    "    # all_weights_df=pd.concat([all_weights_df,weights_df])\n",
    "    all_weights_df.loc[sim_timestamp] = weights_df.loc[sim_timestamp]\n",
    "\n",
    "\n",
    "# copy wanted actuals\n",
    "all_actuals_df = grid.actuals.loc[sim_timestamps].drop(\n",
    "    \"TotalPower\", axis=1).copy()\n",
    "# match index name to all_scenarios_df\n",
    "all_actuals_df.index.name = \"sim_timestamp\"\n",
    "\n",
    "print(\"\\nall_actuals_df:\")\n",
    "all_actuals_df\n",
    "print(\"\\nall_scenarios_df:\")\n",
    "all_scenarios_df\n",
    "print(\"\\nall_weights_df:\")\n",
    "all_weights_df\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"elapsed time = {}\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Users/isatkaus/projects/ecp/public-github/powerscenarios/powerscenarios/costs/exago/opflowoptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# total power\n",
    "# choose sim_timestamp for which to plot all scenarios\n",
    "# sim_timestamp = sim_timestamps[0]\n",
    "\n",
    "# all needed period timestamps: t0,t1,...\n",
    "timestamps = pd.date_range(\n",
    "    start=sim_timestamp - pd.Timedelta(\"5min\"), periods=n_periods + 1, freq=\"5min\"\n",
    ")\n",
    "plot_df = pd.DataFrame(index=timestamps, columns=range(1, n_scenarios + 1),)\n",
    "for scenario_nr in range(1, n_scenarios + 1):\n",
    "    s = scenarios_df.loc[(sim_timestamp, scenario_nr,)].sum(axis=1)\n",
    "    s.loc[timestamps[0]] = grid.actuals.loc[timestamps[0]].loc[\"TotalPower\"]\n",
    "\n",
    "    plot_df[scenario_nr] = s\n",
    "\n",
    "# plot_df.iplot()\n",
    "# plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"Total Wind Power\", asImage=True,)\n",
    "plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"Total Wind Power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# power at generators\n",
    "# choose sim_timestamp and scenario nr for which to plot power at generators\n",
    "# sim_timestamp = sim_timestamps[0]\n",
    "scenario_nr = 5\n",
    "\n",
    "# all needed period timestamps: t0,t1,...\n",
    "timestamps = pd.date_range(\n",
    "    start=sim_timestamp - pd.Timedelta(\"5min\"), periods=n_periods + 1, freq=\"5min\"\n",
    ")\n",
    "\n",
    "plot_df = scenarios_df.loc[(sim_timestamp, scenario_nr)]\n",
    "plot_df.loc[timestamps[0]] = grid.actuals.loc[timestamps[0]]\n",
    "plot_df.sort_index(inplace=True)\n",
    "\n",
    "# plot_df.iplot()\n",
    "# plot_df.iplot(xTitle=\"Time\", yTitle=\"MW\", title=\"scenario_nr={}\".format(scenario_nr), asImage=True,)\n",
    "plot_df.iplot(\n",
    "    xTitle=\"Time\",\n",
    "    yTitle=\"MW\",\n",
    "    title=\"Power at generators when scenario_nr={}\".format(scenario_nr),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance sampling weights\n",
    "\n",
    "$E_{f}\\left[y\\left(X\\right)\\right]=\\int y\\left(x\\right)f(x)dx=\\int y\\left(x\\right)\\frac{f(x)}{g(x)}g(x)dx=E_{g}\\left[y\\left(X\\right)\\frac{f(X)}{g(X)}\\right]$\n",
    "\n",
    "\n",
    "$E\\left[y\\left(X\\right)\\right]\\approx\\frac{1}{N_{s}}{\\displaystyle \\sum_{i=1}^{N_{s}}y\\left(X_{i}\\right)} \\;\\;\\; \\textrm{with} \\;\\; X_i \\; \\textrm{from} \\;\\;f$\n",
    "\n",
    "\n",
    "$E\\left[y\\left(X\\right)\\frac{f(X)}{g(X)}\\right]\\approx\\frac{1}{N_{s}}{\\displaystyle \\sum_{i=1}^{N_{s}}y\\left(X_{i}\\right)\\frac{f(X_i)}{g(X_i)}} \\;\\;\\; \\textrm{with} \\;\\; X_i \\; \\textrm{from} \\;\\;g$\n",
    "\n",
    "$\\frac{f(X_i)}{g(X_i)} = w_i \\;\\; \\textrm{are importance sampling weights} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate by bus (occasionally needed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_actuals_df = all_actuals_df.groupby(lambda x: x.split(\"_\")[0], axis=1).sum()\n",
    "# all_scenarios_df = all_scenarios_df.groupby(lambda x: x.split(\"_\")[0], axis=1).sum()\n",
    "# all_actuals_df\n",
    "# all_scenarios_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop tz  (occasionally needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # drop tz from actuals\n",
    "# all_actuals_df.index = all_actuals_df.index.map(lambda t: t.replace(tzinfo=None))\n",
    "\n",
    "# # drop tz from scenarios\n",
    "# all_scenarios_df.index=all_scenarios_df.index.map(\n",
    "#     lambda t: (t[0].replace(tzinfo=None), t[1], t[2].replace(tzinfo=None))\n",
    "# )\n",
    "\n",
    "# all_actuals_df\n",
    "# all_scenarios_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = all_scenarios_df.copy()\n",
    "# # if scenarios are single period, we can drop period_timestamp index level\n",
    "# if n_periods == 1:\n",
    "#     df.index=df.index.droplevel(\"period_timestamp\")\n",
    "\n",
    "# filename = './scenarios.csv'\n",
    "# print(\"\\nsaving all_scenarios_df to {}\".format(filename))\n",
    "# df\n",
    "# df.to_csv(filename)\n",
    "\n",
    "# # save weights\n",
    "# filename = './weights.csv'\n",
    "# print(\"\\nsaving all_weights_df to {}\".format(filename))\n",
    "# all_weights_df\n",
    "# all_weights_df.to_csv(filename)\n",
    "\n",
    "\n",
    "# # take actuals corresponding to scenarios\n",
    "# df=all_actuals_df\n",
    "# df.index=df.index.rename(\"sim_timestamp\")\n",
    "# filename = './actuals.csv'\n",
    "# print(\"\\nsaving actuals to {}\".format(filename))\n",
    "# df\n",
    "# df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving as .aux \n",
    "will produce a separate .aux file for each actual and each senario period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # save_dir = \"/Users/isatkaus/projects/ecp/powerscenarios/data/scenarios-data/tamara/\"\n",
    "# save_dir = \"./aux/\"\n",
    "\n",
    "\n",
    "# ###################################### save scenarios\n",
    "# for i in range(len(all_scenarios_df)):\n",
    "\n",
    "#     s = all_scenarios_df.iloc[i]\n",
    "\n",
    "#     # create filename from multiindex, option 1: <simulation timestamp>_<scenario number>_<period timestamp>\n",
    "#     # filename = str(s.name[0]).replace(' ','-')+'_'+str(s.name[1])+'_'+str(s.name[2]).replace(' ','-')\n",
    "\n",
    "#     # create filename from multiindex, option 2: <simulation timestamp>_<scenario number>_<period number>\n",
    "#     filename = (\n",
    "#         str(s.name[0]).replace(\" \", \"-\")\n",
    "#         + \"_S\"\n",
    "#         + str(s.name[1])\n",
    "#         + \"_P\"\n",
    "#         + str(((s.name[2] - s.name[0]).seconds // 60) // 5 + 1)\n",
    "#         + \".aux\"\n",
    "#     )\n",
    "\n",
    "#     filename = save_dir + filename\n",
    "\n",
    "#     delimiter = \" \"\n",
    "#     delimiter = \"\\t\"\n",
    "\n",
    "#     with open(filename, \"w\") as f:\n",
    "#         # .aux header\n",
    "#         _ = f.write(\"DATA (Gen, [BusNum,GenID,GenMW,GenStatus])\\n\")\n",
    "#         _ = f.write(\"{\\n\")\n",
    "#         # each series entry is one line\n",
    "#         for k in range(len(s)):\n",
    "#             _ = f.write(\n",
    "#                 delimiter\n",
    "#                 + s.index[k].split(\"_\")[0]\n",
    "#                 + delimiter\n",
    "#                 + '\"'\n",
    "#                 + s.index[k].split(\"_\")[2]\n",
    "#                 + '\"'\n",
    "#                 + delimiter\n",
    "#                 + str(s[k])\n",
    "#                 + delimiter\n",
    "#                 + '\"Closed\"'\n",
    "#                 + \"\\n\"\n",
    "#             )\n",
    "#         # .aux EOF\n",
    "#         _ = f.write(\"}\\n\")\n",
    "\n",
    "\n",
    "# ######################################## save actuals\n",
    "\n",
    "# for i in range(len(all_actuals_df)):\n",
    "\n",
    "#     s = all_actuals_df.iloc[i]\n",
    "\n",
    "#     # create filename from multiindex, option 2: <simulation timestamp>_<scenario number>_<period number>\n",
    "#     filename = str(s.name).replace(\" \", \"-\") + \"_A\" + \".aux\"\n",
    "\n",
    "#     filename = save_dir + filename\n",
    "\n",
    "#     delimiter = \" \"\n",
    "#     delimiter = \"\\t\"\n",
    "\n",
    "#     with open(filename, \"w\") as f:\n",
    "#         # .aux header\n",
    "#         _ = f.write(\"DATA (Gen, [BusNum,GenID,GenMW,GenStatus])\\n\")\n",
    "#         _ = f.write(\"{\\n\")\n",
    "#         # each series entry is one line\n",
    "#         for k in range(len(s)):\n",
    "#             _ = f.write(\n",
    "#                 delimiter\n",
    "#                 + s.index[k].split(\"_\")[0]\n",
    "#                 + delimiter\n",
    "#                 + '\"'\n",
    "#                 + s.index[k].split(\"_\")[2]\n",
    "#                 + '\"'\n",
    "#                 + delimiter\n",
    "#                 + str(s[k])\n",
    "#                 + delimiter\n",
    "#                 + '\"Closed\"'\n",
    "#                 + \"\\n\"\n",
    "#             )\n",
    "#         # .aux EOF\n",
    "#         _ = f.write(\"}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
